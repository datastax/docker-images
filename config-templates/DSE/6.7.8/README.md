# Use these default config templates to customize your environment and use with the [DSE Config Volume](https://docs.datastax.com/en/docker/doc/docker/docker67/dockerDSEVolumes.html).  


# Cassandra

```
cassandra-env.sh
cassandra-rackdc.properties
cassandra-topology.properties
cassandra-topology.yaml
cassandra.yaml
commitlog_archiving.properties
jvm.options
log4j-example.properties
log4j-example.properties
logback-no-op.xml
logback-tools.xml
logback.xml
metrics-reporter-config-sample.yaml
```

# DSE

```
dse-env.sh
dse.default
dse.yaml
logback-dsefs-shell.xml
```

# Graph

```
logback-gremlin-server.xml
remote-objects.yaml
remote.yaml
```

# Hadoop Client

```
hadoop-config.sh
hadoop-env.sh
hadoop-metrics.properties
hadoop-metrics2.properties
hdfs-config.sh
httpfs-config.sh
httpfs-env.sh
httpfs-log4j.properties
kms-config.sh
kms-env.sh
kms-log4j.properties
log4j.properties
mapred-config.sh
mapred-env.sh
yarn-config.sh
yarn-env.sh
```

# Search (Solr)

```
exclude.hosts
```

# Analytics (Spark)

```
docker.properties.template
dse-spark-env.sh
dse.conf
fairscheduler.xml.template
hive-site.xml
java-opts
logback-server.xml
logback-spark-beeline.xml
logback-spark-executor.xml
logback-spark-server.xml
logback-spark-shell.xml
logback-spark-sql.xml
logback-spark.xml
logback-sparkR.xml
metrics.properties.template
spark-config.sh
spark-daemon-defaults.conf
spark-defaults.conf
spark-env.sh
```

# Tomcat

```
catalina.properties
logging.properties
server.xml
```
