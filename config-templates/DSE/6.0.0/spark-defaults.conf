# Default system properties included when running any Spark application, including Spark Submit,
# Spark SQL, Spark SQL ThriftServer, PySpark, Spark Shell, or Spark R.

# Note that this file is not used by Spark Standalone based DSE Resource Manager which is running
# on DSE server side.

# DSE related Settings
spark.cassandra.connection.factory          com.datastax.bdp.spark.DseCassandraConnectionFactory
spark.cassandra.auth.conf.factory           com.datastax.bdp.spark.DseAuthConfFactory
spark.extraListeners                        com.datastax.bdp.spark.reporting.DseSparkListener
spark.SparkHadoopUtil                       org.apache.hadoop.security.DseSparkHadoopUtil

spark.sql.catalogImplementation             hive
spark.sql.hive.metastore.barrierPrefixes    org.apache.spark.sql.cassandra

# Mutual authentication and encryption for Spark application. Unlike in standalone mode, those
# settings are per application. Authentication key is generated automatically using secure random
# number generator whenever spark.authenticate is set to true. The secret key is different for each
# single application. It is allowed to have applications running with authentication enabled and
# disabled at the same time.
spark.authenticate                          false
spark.network.crypto.enabled                false
spark.network.crypto.saslFallback           false
spark.authenticate.secretBitLength          256
spark.authenticate.enableSaslEncryption     false
spark.network.sasl.serverAlwaysEncrypt      true

# Regex to decide which Spark configuration properties and environment variables contain sensitive 
# information and therefore should be redacted when they are listed in any way.
spark.redaction.regex                       (?i)secret|password|token

spark.hadoop.com.datastax.bdp.fs.client.authentication.factory  com.datastax.bdp.fs.hadoop.DseRestClientAuthProviderBuilderFactory

# When DSE Spark is started, it fetches some configuration settings from DSE node
# This operation can be retried a couple of times, as defined by this property
# The delay between subsequent retries starts from 1 second and is doubled with each trial (limited at 10 seconds)
spark.dse.configuration.fetch.retries   2

# Increase retry threshold for greater stability
spark.task.maxFailures	10
